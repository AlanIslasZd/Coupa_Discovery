{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "muwv5ljqs5jt2pfiemyn",
   "authorId": "7811118855564",
   "authorName": "ALAN.ISLASMORRIS@ZENDESK.COM",
   "authorEmail": "alan.islasmorris@zendesk.com",
   "sessionId": "6e23e040-c22a-47f9-8043-a049f2b980c6",
   "lastEditTime": 1764890100708
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "12afce32-dc17-4fa8-a913-410fde48e56b",
   "metadata": {
    "language": "sql",
    "name": "cell8"
   },
   "outputs": [],
   "source": "NAME\nCOUPA_INVOICE_HEADER_SCD2_ID\nCUSTOM_FIELDS\nCANCELED\nCASH_ACCOUNTING_SCHEME_REFERENCE\nCHANNEL\nCLEARANCE_DOCUMENT\nCOMMENTS\nCOMPLIANT\nCONFIRMATION\nCOUPA_ACCELERATE_STATUS\nCREDIT_REASON\nCUSTOMS_DECLARATION_NUMBER\nCUSTOMS_OFFICE\nDELIVERY_NUMBER\nDISPUTE_METHOD\nDOCUMENT_TYPE\nEARLY_PAYMENT_PROVISIONS\nEXPORTED\nFOLIO_NUMBER\nFORM_OF_PAYMENT\nIMAGE_SCAN\nIMAGE_SCAN_URL\nINBOX_NAME\nINTERNAL_NOTE\nINVOICE_NUMBER\nISSUANCE_PLACE\nLAST_EXPORTED_AT\nLATE_PAYMENT_PENALTIES\nLINE_LEVEL_TAXATION\nMARGIN_SCHEME\nNET_DUE_DATE\nORIGINAL_INVOICE_NUMBER\nPAID\nPAYMENT_CHANNEL\nPAYMENT_METHOD\nPAYMENT_NOTES\nPAYMENT_ORDER_REFERENCE\nREVERSE_CHARGE_REFERENCE\nSELF_BILLING_REFERENCE\nSENDER_EMAIL\nSERIES\nSHOW_TAX_INFORMATION\nSTATUS\nSUPPLIER_CREATED\nSUPPLIER_NOTE\nTAX_AMOUNT_ENGINE\nTAX_RATE\nTOLERANCE_FAILURES\nTYPE_OF_RECEIPT\nTYPE_OF_RELATIONSHIP\nUSE_OF_INVOICE\nZDP_META_SOURCE_ACCOUNT\nDBT_SCD_ID",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "source": "use database CLEANSED;\nUSE SCHEMA COUPA;\nSELECT \n    COUPA_INVOICE_LINE_SCD2_ID,\n    CUSTOM_FIELDS,\n    BILLING_NOTE,\n    CATEGORY,\n    COMPANY_UOM,\n    CUSTOMS_DECLARATION_NUMBER,\n    DEDUCTIBILITY,\n    DELIVERY_NOTE_NUMBER,\n    DESCRIPTION,\n    HSN_SAC_CODE,\n    LINE_TYPE,\n    MATCH_REFERENCE,\n    ORDER_HEADER_NUM,\n    ORDER_LINE_NUM,\n    ORDER_LINE_SOURCE_PART_NUM,\n    ORIGINAL_DATE_OF_SUPPLY,\n    PO_NUMBER,\n    PROPERTY_TAX_ACCOUNT,\n    SOURCE_PART_NUM,\n    STATUS,\n    SUBCATEGORY,\n    TAX_AMOUNT_ENGINE,\n    TAX_DESCRIPTION,\n    TAX_LOCATION,\n    TAX_RATE,\n    TYPE,\n    UNSPSC,\n    ZDP_META_SOURCE_ACCOUNT,\n    DBT_SCD_ID\nFROM COUPA_INVOICE_LINE_BCV\nWHERE DATE(CREATED_AT) > '2025-11-30'",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "9b3992c8-451d-4f71-a9db-96befc308e21",
   "metadata": {
    "language": "python",
    "name": "cell4"
   },
   "outputs": [],
   "source": "import pandas as pd\ndf = cell1.to_pandas()",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "01f1450b-e53f-4284-9f59-746b970e0199",
   "metadata": {
    "language": "python",
    "name": "cell7"
   },
   "outputs": [],
   "source": "def generate_data_snapshot(df):\n    \"\"\"\n    Generates a 360Â° data snapshot for a given DataFrame.\n    Returns the summary DataFrame.\n    \"\"\"\n    summary_data = []\n    row_count = len(df)\n    \n    for col in df.columns:\n        col_data = df[col]\n        dtype = col_data.dtype\n        non_null_ct = col_data.count()\n        null_ct = row_count - non_null_ct\n        distinct_ct = col_data.nunique()\n        \n        # Base stats\n        stats = {\n            'ATTRIBUTE': col,\n            'DTYPE': str(dtype),\n            'ROW_COUNT': row_count,\n            'NON_NULL_CT': non_null_ct,\n            'NULL_CT': null_ct,\n            'DISTINCT_CT': distinct_ct,\n            'DETAILS': '' # Placeholder for type-specific stats\n        }\n        \n        # Type specific stats\n        if pd.api.types.is_numeric_dtype(col_data):\n            # Numeric: min/median/mean/max, P90/P95\n            desc = col_data.describe(percentiles=[.5, .9, .95])\n            stats['DETAILS'] = (\n                f\"Min: {desc['min']:.2f}, Med: {desc['50%']:.2f}, Mean: {desc['mean']:.2f}, \"\n                f\"Max: {desc['max']:.2f}, P90: {desc['90%']:.2f}, P95: {desc['95%']:.2f}\"\n            )\n        elif pd.api.types.is_datetime64_any_dtype(col_data):\n            # Date: min/max\n            stats['DETAILS'] = f\"Min: {col_data.min()}, Max: {col_data.max()}\"\n        else:\n            # Categorical: top 3 values with shares\n            top_counts = col_data.value_counts(normalize=True).head(3)\n            top_strs = [f\"{val} ({pct:.1%})\" for val, pct in top_counts.items()]\n            stats['DETAILS'] = \"Top 3: \" + \", \".join(top_strs)\n            \n        summary_data.append(stats)\n        \n    summary_df = pd.DataFrame(summary_data)\n    \n    return summary_df\n# Example Usage (Uncomment to run with your dataframe)\n# df = pd.read_csv('your_data.csv')\n# generate_data_snapshot(df)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a4b44b4f-f821-4b45-a512-88467d931a7e",
   "metadata": {
    "language": "python",
    "name": "cell5"
   },
   "outputs": [],
   "source": "# Define the function to get unique values for specified columns\ndef unique_values(df, list_of_columns):\n    \"\"\"\n    Get unique values for each column in the list.\n    Excludes columns where all values are NULL.\n    \n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        The dataframe to analyze\n    list_of_columns : list\n        List of column names to analyze\n    \n    Returns:\n    --------\n    tuple: (results_df, excluded_columns)\n        - results_df: DataFrame with columns: column_name, unique_count, unique_values (as string)\n        - excluded_columns: List of columns that were all NULL\n    \"\"\"\n    results = []\n    excluded_columns = []\n    \n    for col in list_of_columns:\n        if col in df.columns:\n            # Check if all values are NULL/NaN\n            if df[col].isna().all():\n                excluded_columns.append(col)\n                print(f\"Excluding '{col}' - all values are NULL\")\n                continue\n            \n            # Get unique values, excluding None/NaN\n            unique_vals = df[col].dropna().unique()\n            unique_count = len(unique_vals)\n            \n            # Convert to string and join with ' | ' separator\n            unique_vals_str = ' | '.join([str(val) for val in sorted(unique_vals)])\n            \n            results.append({\n                'column_name': col,\n                'unique_count': unique_count,\n                'unique_values': unique_vals_str\n            })\n        else:\n            print(f\"Warning: Column '{col}' not found in dataframe\")\n    \n    return pd.DataFrame(results), excluded_columns\n\n#print(\"Function 'unique_values' defined successfully!\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c24d128f-c27b-493f-88d8-df0e894f215d",
   "metadata": {
    "language": "python",
    "name": "cell6"
   },
   "outputs": [],
   "source": "# Define function to get top N most frequent values for each column\ndef top_n_values(df, list_of_columns, top_n=5):\n    \"\"\"\n    Get the top N most frequent values for each column.\n    Returns one row per value per column (exploded format).\n    Excludes columns where all values are NULL.\n    \n    Parameters:\n    -----------\n    df : pandas.DataFrame\n        The dataframe to analyze\n    list_of_columns : list\n        List of column names to analyze\n    top_n : int\n        Number of top values to return per column (default: 5)\n    \n    Returns:\n    --------\n    tuple: (results_df, excluded_columns)\n        - results_df: DataFrame with columns: column_name, rank, value, count, percentage\n        - excluded_columns: List of columns that were all NULL\n    \"\"\"\n    results = []\n    excluded_columns = []\n    \n    for col in list_of_columns:\n        if col in df.columns:\n            # Check if all values are NULL/NaN\n            if df[col].isna().all():\n                excluded_columns.append(col)\n                print(f\"Excluding '{col}' - all values are NULL\")\n                continue\n            \n            # Get value counts for the column\n            value_counts = df[col].value_counts().head(top_n)\n            total_non_null = df[col].notna().sum()\n            \n            # Create one row per top value\n            for rank, (val, count) in enumerate(value_counts.items(), start=1):\n                percentage = (count / total_non_null * 100) if total_non_null > 0 else 0\n                results.append({\n                    'column_name': col,\n                    'rank': rank,\n                    'value': str(val),\n                    'count': count,\n                    'percentage': round(percentage, 2)\n                })\n        else:\n            print(f\"Warning: Column '{col}' not found in dataframe\")\n    \n    return pd.DataFrame(results), excluded_columns\n\nprint(\"Function 'top_n_values' defined successfully!\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "language": "python",
    "name": "cell2"
   },
   "source": "# Define the list of columns to analyze\ncolumns_to_analyze = [\n    'COUPA_INVOICE_LINE_SCD2_ID',\n    'CUSTOM_FIELDS',\n    'BILLING_NOTE',\n    'CATEGORY',\n    'COMPANY_UOM',\n    'CUSTOMS_DECLARATION_NUMBER',\n    'DEDUCTIBILITY',\n    'DELIVERY_NOTE_NUMBER',\n    'DESCRIPTION',\n    'HSN_SAC_CODE',\n    'LINE_TYPE',\n    'MATCH_REFERENCE',\n    'ORDER_HEADER_NUM',\n    'ORDER_LINE_NUM',\n    'ORDER_LINE_SOURCE_PART_NUM',\n    'ORIGINAL_DATE_OF_SUPPLY',\n    'PO_NUMBER',\n    'PROPERTY_TAX_ACCOUNT',\n    'SOURCE_PART_NUM',\n    'STATUS',\n    'SUBCATEGORY',\n    'TAX_AMOUNT_ENGINE',\n    'TAX_DESCRIPTION',\n    'TAX_LOCATION',\n    'TAX_RATE',\n    'TYPE',\n    'UNSPSC',\n    'ZDP_META_SOURCE_ACCOUNT',\n    'DBT_SCD_ID'\n]\n\n# Run the analysis\ntop_results_df, top_excluded_columns = top_n_values(df, columns_to_analyze, top_n=5)\n\n# Display results\nprint(f\"\\nTop Values Analysis complete!\")\nprint(f\"Total rows (top values across all columns): {len(top_results_df)}\")\nprint(f\"Columns analyzed: {top_results_df['column_name'].nunique()}\")\nprint(f\"Columns excluded (all NULL): {len(top_excluded_columns)}\")\nif top_excluded_columns:\n    print(f\"\\nExcluded columns: {', '.join(top_excluded_columns)}\")\n\n# Show summary by column\nprint(\"\\nTop values count by column:\")\nprint(top_results_df.groupby('column_name').size().to_frame('top_values_returned'))\n\n# Return the exploded dataframe to render it\ntop_results_df",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "be701d1e-13a3-4a2f-82f0-1f6b2dc70129",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": "generate_data_snapshot(df)",
   "execution_count": null
  }
 ]
}